---
layout: post
title: "[종료] Text 중심 대화 경험의 UX 평가 요소와 검증 방법 연구"
categories: [Project]
image: assets/images/project/cxq.png
author: snuxlab
company: LG전자 홈IoT 평가
featured: true
---

<p>
<br>
<p align="center"><img src="{{site.baseurl}}/assets/images/project/cxq.png"></p>
<br>
LGE의 AI 이니셔티브의 첫 단계로 IoT 허브 앱 ThinQ에 대화형 인터페이스(chat)가 배치되어 생성형 AI 챗봇 '챗씽큐(ChatThinQ)'가 출시될 예정이다. 챗씽큐의 성공을 위해 기능적 성능과 사용 효능감(UX)을 보장해야 한다. 그러나 대화형 인터페이스의 성공 기준은 기존 화면 기반의 위계형 인터페이스와 다르다. 대화형 인터페이스는 화면이든 보이스든 편리한 조작을 넘어 ‘지능’을 의미하므로, 단순히 기능이 성공하는 것보다 ‘대화 경험’이 중요하다. 따라서 ‘나은 기술’이 아닌 ‘다른 기술’로서 대화형 인터랙션의 평가 기준, 특히 UX적 평가 기준을 새롭게 개발한다.
<br><br>
챗씽큐는 커스텀 LLM 서비스로, 홈IoT + LLM이 결합된 챗봇을 평가하기 위한 방법론부터 고민할 필요가 있다. 커스텀 LLM 서비스의 성패는 제네릭 LLM을 서비스 목적에 맞게 잘 커스터마이즈했는가 이다. 즉 서비스 영역에서 발생하는 특화된 질문에 전문성이 깃든 답 또는 수행이 벌어져야 한다. 이를 위해 실제 사용자들에 의해 요청될 법한 다양하고 특수한 상황에서의 실발화들을 수집했다. 실발화를 분석하여 챗씽큐 서비스 영역을 다양한 축으로 나눠보고자 시도했고, LLM을 활용하여 평가를 위한 발화 레퍼런스 세트를 양산했다. 마지막으로 챗씽큐에 대한 휴먼 평가의 특징들을 기반으로 LLM을 활용하여 자동으로 평가할 수 있는 평가 머신을 제작 및 고도화했다.
<br>
</p>

<hr>
참가자: 유지수, 이기훈, 송지은, 이은채 <br>
기간: 2024.05 ~ 2024.08 <br>
협력 기관: LG전자 홈IoT 평가
